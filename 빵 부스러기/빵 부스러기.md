# 🍞 빵 부스러기
>개발 관련 학습 중 하나의 글로 작성하기엔 짧고, <br/>
>버리기엔 아까운 부스러기 정보들을 모아두는 곳. <br/> <br/>
>임시로 작성한게 완성 되면 빵이 되어 나가는 것이다. <br/> 
>1개, 2개, 3개, ... 부스러기 들을 모아 두고 점점 정리해 가는 것이다. <br/>
>정리가 된것은 🍞이 되어 해결.
> ***



<br/>

## 목차


---

**네트워크란?**

- 네트워크란 컴퓨터나 기타 기기들이 데이터를 주고받거나 리소스를 공유하기 위해 유선 또는 무선으로 연결된 통신 체계

**공유기란?**

- 공유기는 하나의 공인 IP 주소를 이용하여 여러 기기가 동시에 인터넷을 사용할 수 있도록 해줍니다. 또한, 공유기에 연결된 기기들은 같은 네트워크에 속한다.

**노드와 엔드 시스템이란?**

- **노드**: 네트워크에 연결된 모든 장치(컴퓨터, 공유기, 라우터 등)를 의미
- **엔드 시스템**: 네트워크의 끝에 위치한 장치로, 최종적으로 데이터를 주고받는 기기(PC, 스마트폰, TV 등)를 말하며, `호스트(Host)`라고도 부른다.
    - 엔드 시스템은 클라이언트(요청을 보내는 장치)와 서버(요청을 처리하고 응답하는 장치)로 구분

**클라이언트-서버 모델이란?**

- **클라이언트**: 서버에 데이터를 요청하는 장치입니다.
- **서버**: 클라이언트의 요청을 처리하고 데이터를 제공하는 장치. ex) 유튜브 영상을 시청할 때, 사용자는 유튜브 서버에 요청을 보내고, 서버가 영상을 전송.

**LAN(Local Area Network)이란?**

- LAN은 집, 학교, 회사 등 제한된 범위 내에서 네트워크를 구축하여 데이터와 리소스를 공유하는 네트워크.
    - 유선 LAN: Ethernet
    - 무선 LAN: Wi-Fi

**ISP(Internet Service Provider)란?**

- ISP는 개인이나 기업이 인터넷을 사용할 수 있도록 연결 서비스를 제공하는 사업자
    - KT, SKT, LG U+

**ISP의 티어(Tier) 구조란?**

- ISP는 규모와 역할에 따라 티어로 나뉜다.
    - **1티어**: 국제적인 네트워크를 보유하며, 모든 인터넷 네트워크에 접근할 수 있습니다. ISP 간 트래픽 비용 없이 데이터를 주고받는다.
    - **2티어**: 국가 또는 지역 단위 네트워크를 운영하며, 1티어 ISP에 비용을 지불하고 트래픽을 전달. (예: KT, SKT, LG U+)
    - **3티어**: 소규모 지역 ISP로, 2티어 ISP에 비용을 내고 인터넷을 제공

**ISP 간 네트워크 연결은 어떻게 이루어지나요?**

- 서로 다른 ISP 네트워크는 라우터를 통해 연결. 라우터는 목적지 네트워크를 찾아 데이터를 전달하는 역할
- 1티어 → 2티어 → 3티어 순서로 데이터를 전달하여 최종 목적지에 도달.

**인터넷은 어떻게 동작하나요?**

- 사용자가 데이터를 요청하면, ISP의 라우터로 데이터가 전송.
- 라우터는 목적지 네트워크를 찾기 위해 상위 ISP(티어 1, 2 등)로 데이터를 전달.
- 여러 ISP의 네트워크를 거쳐 최종적으로 목적지 네트워크(기업, 웹사이트 등)에 도착.
- 목적지 서버에서 데이터를 보내면 같은 과정을 거쳐 사용자에게 응답이 도착.

**World Wide Web(WWW)이란?**

- World Wide Web(WWW)은 인터넷 상에서 정보를 링크를 통해 효율적으로 접근할 수 있도록 설계된 전 지구적 정보 시스템.

**인터넷이란?**

- **인터넷**: 글로벌 네트워크 인프라로, 여러 네트워크가 연결된 거대한 시스템
- **웹**: 인터넷을 기반으로 동작하는 정보 시스템으로, 웹 브라우저를 통해 하이퍼링크를 이용해 정보를 검색할 수 있다.

**HTTP 프로토콜이란?**

- World Wide Web은 인터넷 상에서 정보를 링크를 통해 효율적으로 접근할 수 있도록 설계된 전 지구적 정보 시스템.

**HTTP와 HTTPS의 차이는?**

**HTTP**: 텍스트 데이터를 암호화 없이 주고받는 프로토콜

- 보안 취약점 존재 → 도청, 위장 공격(스푸핑), 변조 가능

**HTTPS**: SSL/TLS 암호화를 적용한 HTTP

- 데이터를 암호화하여 보안 강화
- 중간자가 데이터를 가로채도 해독 불가능

**HTTP vs HTTPS 비교**

**보안**

- HTTP: 암호화 없음 → 도청, 변조 위험
- HTTPS: SSL/TLS 암호화 적용 → 안전한 통신

**포트**

- HTTP: 80번
- HTTPS: 443번

**데이터 암호화**

- HTTP: 없음 (평문 전송)
- HTTPS: 있음 (공개키 & 대칭키 암호화)

**속도**

- HTTP: 상대적으로 빠름
- HTTPS: 암호화 과정 추가로 속도 약간 저하

**사용 사례**

- HTTP: 일반 웹페이지, 공개 정보 제공
- HTTPS: 로그인, 금융 거래, 개인정보 보호 필요 서비스

**HTTP의 보안 취약점은 무엇인가요?**

**도청 가능(Eavesdropping)**

- 데이터가 암호화되지 않아서 중간에서 감청 가능
- 해커가 패킷을 가로채면 로그인 정보, 카드 정보 등이 노출될 위험

**위장 공격(Spoofing)**

- 클라이언트와 서버 간의 통신을 가로채 공격자가 위장할 수 있음
- 사용자는 신뢰할 수 없는 사이트와 통신하게 됨

**변조 가능(Tampering)**

- 전송 중인 데이터를 해커가 변조할 수 있음
- 예: 다운로드 파일을 악성코드로 변경

이러한 문제를 해결하기 위해 HTTPS를 사용합니다.

**HTTPS는 어떻게 보안을 강화하나요?**

HTTPS는 SSL/TLS 암호화로 보안을 강화 원리.

1. 데이터 암호화 (Encryption) → 공개키 암호화 & 대칭키 암호화 사용
2. 무결성 보장 (Integrity) → 데이터 변조 방지 (MAC, 전자서명 사용)
3. 신원 확인 (Authentication) → CA 인증서를 통한 신뢰성 보장

HTTPS는 데이터 기밀성, 무결성, 신뢰성을 모두 보장.

**HTTPS 통신 과정(SSL/TLS Handshake)은 어떻게 이루어지나요?**

1. 서버가 CA 인증서를 제공
2. 클라이언트가 인증서를 검증하고, 서버의 공개키 획득
3. 클라이언트가 대칭키를 생성한 후, 서버의 공개키로 암호화하여 전송

 4. 서버가 개인키로 복호화하여 대칭키 획득

1. 이후부터는 생성된 대칭키를 사용하여 암호화된 통신 진행

초기에는 공개키 암호화, 이후에는 속도가 빠른 대칭키 암호화 사용

**SSL과 TLS의 차이점은?**

- SSL은 초기 보안 프로토콜이며, 보안 취약점(키 노출, 다운그레이드 공격)으로 인해 더 이상 사용되지 않는다.
- TLS는 SSL을 개선한 프로토콜로, 강력한 암호화(AES-GCM)와 향상된 핸드셰이크(TLS 1.3에서 1-RTT)를 제공한다.

현재 TLS 1.2와 TLS 1.3이 표준으로 사용된다.

**SSL 2.0이 보안적으로 취약한 이유?**

- **암호화 키 노출:** 핸드셰이크 과정에서 Master Secret을 평문으로 전송하여 키 탈취 가능.
- **메시지 인증 부족:** 데이터 변조를 방지하는 MAC이 없어 공격자가 중간에서 조작 가능.
- **다운그레이드 공격 가능:** 강한 암호화를 약한 암호화로 강제 변경 가능.
- **취약한 암호화 알고리즘:** 쉽게 크랙 가능한 알고리즘 사용(RC2, RC4).

**SSL 3.0에서 POODLE 공격이 발생하는 이유와 해결 방법?**

- **이유:** CBC 모드에서 패딩 검증 방식이 취약하여, 공격자가 패딩 오류를 유도해 암호문을 해독할 수 있음.
- **해결 방법:**
    1. **SSL 3.0 비활성화** 및 TLS 1.2 이상 사용.
    2. **CBC 모드 대신 AES-GCM** 같은 AEAD 암호화 방식 사용.
    3. **TLS_FALLBACK_SCSV 활성화**하여 다운그레이드 공격 방지.

**SSL 2.0과 SSL 3.0 핸드셰이크 차이?**

- **SSL 2.0:** Master Secret을 평문으로 전송하여 키 탈취 위험.
- **SSL 3.0:** ClientKeyExchange에서 비대칭 암호화를 사용해 보안 강화.
- **추가 차이점:**
    - SSL 3.0은 MAC도입으로 데이터 무결성 강화.
    - 핸드셰이크 과정에서 암호화된 키 교환을 지원하여 보안성을 높임.

**SSL 3.0이 폐기된 이유와 대체 프로토콜?**

- **폐기 이유:** POODLE 공격 취약성, 다운그레이드 공격 위험, 구식 암호화 알고리즘(RC4, MD5) 사용.
- **대체 프로토콜:**
    - TLS 1.2: AES-GCM, SHA-256 지원, 보안 강화.
    - TLS 1.3: CBC 제거, 핸드셰이크 간소화, Forward Secrecy 기본 적용.

**SSL 3.0에서 CBC 모드 문제점과 TLS 해결법?**

- **CBC 모드 문제:**
    - POODLE 공격으로 인해 암호문이 해독될 위험이 있음.
    - 블록 암호화 방식에서 패딩 처리 취약점 존재.
- **TLS 해결 방법:**
    - **TLS 1.2:** AES-GCM 같은 AEAD 방식 도입.
    - **TLS 1.3:** CBC 모드 완전 제거, ChaCha20-Poly1305 추가.

**SSL 3.0 보안 취약점 해결 방법?**

1. **SSL 3.0 비활성화**하고, 최소 TLS 1.2 이상만 사용하도록 서버 설정 변경.
2. **강력한 암호화 알고리즘(AES-GCM, ChaCha20-Poly1305) 사용**.
3. **TLS_FALLBACK_SCSV 활성화**하여 다운그레이드 공격 방지.
4. **HSTS(HTTP Strict Transport Security) 적용**하여 HTTPS 강제 사용.

**TLS 1.3이 이전 버전과 비교해 개선된 점?**

- **핸드셰이크 속도 개선:**
    - TLS 1.2는 2-RTT 필요 → **TLS 1.3은 1-RTT로 줄여 속도 향상**.
    - 0-RTT 기능 도입 → 세션 재사용 시 추가 핸드셰이크 없이 즉시 연결 가능.
- **보안 강화:**
    - CBC, RSA key exchange 제거 → **AEAD 암호화(AES-GCM) 사용**.
    - **Perfect Forward Secrecy 기본 지원** → 키 탈취 위험 방지.
- **간소화된 암호화 설정:**
    - 복잡한 Cipher Suite 감소 → 보안성 강화.

**TLS 1.0과 TLS 1.1이 보안적으로 취약한 이유는 무엇인가요?**

- TLS 1.0과 1.1은 CBC 패딩 공격에 취약하고, 구식 암호화 알고리즘(RC4)을 사용하여 보안성이 낮다.
- 키 교환 과정이 안전하지 않아 중간자 공격 가능성이 크다. 이 때문에 대부분의 브라우저와 시스템에서 지원이 중단되었습니다.

**TLS 1.2에서 개선된 점은 무엇인가요?**

- TLS 1.2에서는 AES 기반 암호화와 SHA-2 해시 알고리즘을 도입하여 보안성을 강화했고, HMAC를 추가하여 무결성을 보장했다.
- 클라이언트와 서버가 사용할 암호화 알고리즘을 협상할 수 있는 기능을 추가하여 유연성을 높였다.

**TLS 1.3이 TLS 1.2와 비교했을 때 개선된 점은 무엇인가요?**

- TLS 1.3에서는 핸드셰이크 과정을 단순화하여 성능을 개선하고, 구식 및 취약한 암호화 알고리즘(RC4, SHA-1, MD5 등)을 제거했다.
- **0-RTT(Zero Round Trip Time)** 기능을 추가하여 재연결 속도를 향상시켰고, PFS를 기본 적용하여 보안성을 더욱 강화했다.

**TLS/SSL Handshake 과정은 어떻게 진행되나요?**

TLS/SSL Handshake는 다음 9단계로 진행됩니다.

1. 클라이언트 → 서버 (Client Hello)
    - 클라이언트가 TLS 버전, 암호화 알고리즘 목록, 압축 방식 등의 정보를 보냄
2. 서버 → 클라이언트 (Server Hello)
    - 서버가 TLS 버전, 선택한 암호화 알고리즘, CA 인증서(공개키 포함)를 응답
3. 클라이언트 → CA 인증서 검증
    - 클라이언트가 CA 인증서를 확인하여 서버의 신뢰성을 검증
4. 클라이언트 → 서버 (Pre-Master Secret 생성 및 전송)
    - 클라이언트가 대칭키 생성을 위한 난수(Pre-Master Secret)를 생성하고, 서버의 공개키로 암호화하여 전송

5. 서버 → 클라이언트 (Pre-Master Secret 복호화)

- 서버가 자신의 개인키(Private Key)로 복호화하여 난수를 획득

6. 클라이언트 & 서버 (대칭키 생성)

- 클라이언트와 서버가 같은 대칭키(Session Key)를 생성
1. 클라이언트 → 서버 (Finished 메시지 전송)
    - 클라이언트가 Handshake 완료 메시지를 대칭키로 암호화하여 서버에 전송
2. 서버 → 클라이언트 (Finished 메시지 응답)
    - 서버도 같은 방식으로 응답하여 Handshake 완료
3. 보안 통신 시작
    - 이후 모든 데이터는 대칭키로 암호화하여 안전하게 통신

TLS/SSL Handshake가 완료되면, 보안이 강화된 HTTPS 통신이 시작.

**SSL/TLS에서 공개키 암호화와 대칭키 암호화의 차이는?**

공개키 암호화

- 한 쌍의 키(공개키 & 개인키)를 사용
- 서버의 공개키로 암호화하고, 서버의 개인키로 복호화
- 속도가 느림 → HTTPS 초기 Handshake 과정에서만 사용

대칭키 암호화

- 하나의 키를 공유하여 데이터를 암호화 & 복호화
- 속도가 빠름 → Handshake 후 본격적인 데이터 전송에서 사용

HTTPS는 성능과 보안을 위해 공개키 & 대칭키 암호화를 함께 사용.

**TLS/SSL Handshake에서 공개키 암호화와 대칭키 암호화를 함께 사용하는 이유는?**

공개키 암호화 (비대칭 암호화)

- 초기 Handshake 과정
- 보안성이 높지만 속도가 느림 (서버 공개키로 암호화, 서버 개인키로 복호화)

대칭키 암호화

- Handshake 이후 데이터 전송
- 속도가 빠름, 성능 최적화 가능 (동일한 대칭키로 암호화 및 복호화)

초기에는 공개키 암호화로 대칭키를 교환하고, 이후에는 성능이 좋은 대칭키 암호화를 사용합니다.

**TLS/SSL에서 CA 인증서의 역할은 무엇인가요?**

CA(Certificate Authority) 인증서는 서버의 신뢰성을 검증하는 역할

- CA(인증 기관)가 발급한 인증서는 공개키가 신뢰할 수 있는 서버의 것인지 확인하는 역할
- 클라이언트는 CA의 공개키로 인증서를 검증하여 서버가 신뢰할 수 있는지 판단
- 위조된 서버와의 연결(중간자 공격)을 방지

HTTPS에서는 신뢰할 수 있는 CA 인증서를 사용해야 보안이 유지됩니다.

**TLS/SSL Handshake 과정에서 클라이언트 인증서는 언제 사용되나요?**

일반적인 HTTPS에서는 서버 인증서만 필요하지만, 클라이언트 인증서도 필요한 경우가 있다.

- **서버 인증서 목적**: 클라이언트가 서버를 신뢰하도록 인증
- **클라이언트 인증서 목적**: 서버가 클라이언트를 신뢰하도록 인증

사용 사례

- 대부분의 HTTPS 웹사이트 (e.g. 은행, 쇼핑몰)

- 보안이 중요한 내부 시스템 (e.g. 사내 인트라넷, VPN)

클라이언트 인증서는 보안이 중요한 환경에서 추가 인증 방식으로 사용.

**HTTPS에서 인증서는 왜 필요한가요?**

HTTPS에서 인증서는 신뢰할 수 있는 서버임을 보장.

- CA(Certificate Authority) 인증 기관이 발급한 SSL/TLS 인증서를 사용하여 서버의 신뢰성을 증명
- 클라이언트는 CA의 공개키를 사용하여 인증서를 검증하고, 악성 사이트와의 연결을 방지

HTTPS는 인증서를 통해 피싱 사이트, 중간자 공격을 방지.

**HTTPS는 무조건 안전한가요?**

HTTPS도 100% 안전하지는 않다.

1. 신뢰할 수 없는 CA(인증 기관)를 통한 위조 인증서 가능
2. 자체 서명된 인증서(Self-Signed Certificate)는 보안이 취약
3. 브라우저에 ‘안전하지 않은 사이트’ 경고가 뜰 수 있음
4. 피싱 공격(HTTPS를 사용한 가짜 사이트)

HTTPS를 사용하더라도, 신뢰할 수 있는 CA 인증서를 확인해야 한다.

**HTTPS를 사용하면 성능이 저하되나요?**

HTTPS는 암호화로 인해 약간의 성능 저하가 있지만, 최적화 기법으로 극복할 수 있다.

1. SSL/TLS Handshake 과정이 추가됨 → 최초 연결 속도가 느려짐
2. 하지만 이후에는 세션 재사용으로 속도를 최적화
3. HTTP/2 지원으로 성능 최적화 (다중 요청 처리 가능)

HTTPS는 성능 저하가 크지 않으며, 보안성을 고려하면 반드시 사용해야 합니다.

**WWW를 구성하는 핵심 기술은?**

- HTML → 웹 문서를 작성하는 언어
- HTTP → 웹 문서를 주고받는 프로토콜
- URL → 웹 문서의 주소를 지정하는 방식

**IP 프로토콜이란?**

- IP는 인터넷에서 지정한 IP 주소로 데이터를 전달하는 역할을 하는 프로토콜이다.
    - 데이터를 패킷 단위로 나누어 전송한다.

**패킷이란?**

- 패킷은 데이터를 작은 단위로 나누어 전송하는 방식으로, 마치 택배 박스를 나눠 보내듯이 작동한다.
    - 데이터는 패킷 단위로 분할되어 목적지까지 전송되며,도착한 후 다시 조립되어 원래 데이터로 복원된다.

**IP 프로토콜의 문제점은?**

- 상대 서버의 상태를 확인하지 않고 전송 → 서버가 꺼져 있어도 패킷을 보냄
- 패킷 손실 가능성 → 네트워크 장애나 물리적 문제(예: 케이블 손상) 발생 시 패킷이 유실될 수 있음
- 패킷의 순서 보장 안 됨 → 패킷이 서로 다른 경로로 이동하면서 순서가 뒤바뀔 수 있음

**큰 데이터는 어떻게 전송되나요?**

- 큰 데이터는 작은 패킷으로 나누어 전송되며,각 패킷이 다른 경로를 거쳐 도착할 수도 있고, 순서가 뒤바뀔 수도 있다.
- 따라서, 이를 해결해 주는 TCP 프로토콜이 필요하다.

**OSI 7계층이란?**

- OSI 7계층은 네트워크 기능을 계층별로 분리하여 구조화한 모델이다.
    - **L1 - 물리 계층 (Physical)**
        - 물리적 신호 전송 (비트 단위)
        - 전기 신호, 광 신호
    - **L2 - 데이터 링크 계층 (Data Link)**
        - 직접 연결된 노드 간 데이터 전송
        - Ethernet, MAC, ARP
    - **L3 - 네트워크 계층 (Network)**
        - 호스트 간 데이터 전달, 최적 경로 선택
        - IP, ICMP, ARP
    - **L4 - 전송 계층 (Transport)**
        - 애플리케이션 간 데이터 전송, 오류 검출
        - TCP, UDP
    - **L5 - 세션 계층 (Session)**
        - 세션 설정, 유지, 종료
        - NetBIOS, RPC
    - **L6 - 표현 계층 (Presentation)**
        - 데이터 인코딩, 압축, 암호화
        - JPEG, ASCII, SSL/TLS
    - **L7 - 응용 계층 (Application)**
        - 애플리케이션 간 데이터 전달
        - HTTP, FTP, SMTP, DNS

**응용 계층(Application Layer)의 역할은 무엇인가요?**

L7 - 응용 계층 (Application Layer)

응용 계층은 애플리케이션 간의 데이터 교환을 담당하며, 사용자가 네트워크를 활용할 수 있도록 한다.

대표 프로토콜:

- HTTP: 웹 페이지 전송
- DNS: 도메인 주소를 IP로 변환
- SMTP: 이메일 전송
- FTP: 파일 업로드/다운로드

**L6 - 표현 계층 (Presentation Layer)**

표현 계층은 데이터 변환(인코딩, 암호화, 압축)을 담당한다.

- 예: UTF-8 ↔ ASCII 변환, SSL/TLS 암호화

**L5 - 세션 계층 (Session Layer)**

- 세션 계층은 애플리케이션 간 세션(연결) 생성, 유지, 종료를 담당한다.

**L4 - 전송 계층 (Transport Layer)**

전송 계층은 애플리케이션 간 데이터 전송을 담당하며, 신뢰성 여부에 따라 TCP와 UDP를 사용한다.

- TCP: 신뢰성 있는 데이터 전송(3-Way Handshake, 패킷 순서 보장)
- UDP: 빠른 전송이 필요한 경우 사용(비연결형, 신뢰성 없음)

데이터가 목적지까지 "어떻게 찾아갈지"는 L3의 역할입니다.

**L3 - 네트워크 계층 (Network Layer)**

네트워크 계층은 데이터를 목적지 IP로 라우팅(경로 설정) 한다.

- IP (Internet Protocol) → 목적지 호스트로 데이터 전송
- ICMP (Ping) → 네트워크 상태 확인
- ARP (Address Resolution Protocol) → IP ↔ MAC 주소 변환

라우터(Router)가 이 계층에서 동작한다.

**L2 - 데이터 링크 계층 (Data Link Layer)**

데이터 링크 계층은 같은 네트워크 내에서 노드 간 데이터 전송을 담당한다.

- MAC 주소 기반 통신
- ARP 프로토콜 사용 → IP 주소를 MAC 주소로 변환

스위치(Switch)가 이 계층에서 동작한다.

**L1 - 물리 계층 (Physical Layer)**

물리 계층은 비트 단위로 데이터를 전기적 신호로 변환하여 전송한다.

- 유선: 이더넷 케이블
- 무선: Wi-Fi 신호

**OSI 7계층을 통한 데이터 전송 과정은?**

1. L7 (응용 계층) → 데이터를 생성 (예: HTTP 요청)
2. L6 (표현 계층) → 인코딩/암호화 수행 (예: TLS)
3. L5 (세션 계층) → 세션 연결 유지
4. L4 (전송 계층) → TCP/UDP를 통해 데이터 전송 방식 결정
5. L3 (네트워크 계층) → IP 주소를 기반으로 목적지 설정
6. L2 (데이터 링크 계층) → MAC 주소를 이용해 물리적 장치에 전달
7. L1 (물리 계층) → 데이터를 비트로 변환하여 실제 전송

각 계층은 포장(캡슐화)되어 하위 계층으로 전달된다.

**라우터와 스위치의 차이점은?**

- 라우터 (L3, 네트워크 계층) → IP 주소 기반으로 데이터 경로 설정
- 스위치 (L2, 데이터 링크 계층) → MAC 주소 기반으로 같은 네트워크 내 데이터 전달

라우터는 네트워크 간, 스위치는 네트워크 내에서 데이터 전달을 담당 한다.

**쿠키(Cookie)란?**

쿠키는 클라이언트(웹 브라우저)에 저장되는 작은 데이터 조각으로, 서버가 클라이언트에 정보를 저장하고 이후 요청마다 자동으로 포함하여 서버로 전달된다.

쿠키의 동작 방식:

1. 클라이언트가 로그인 요청 (`POST /login`)
2. 서버가 로그인 성공 후 `Set-Cookie` 헤더로 쿠키 생성 (`Set-Cookie: user=홍길동`)
3. 클라이언트가 이후 요청 시 자동으로 쿠키 포함 (`Cookie: user=홍길동`)
4. 서버는 쿠키를 확인하고 로그인 상태 유지

쿠키를 사용하면 HTTP의 무상태(Stateless) 특성을 보완하여 상태를 유지할 수 있다.

**세션(Session)이란?**

세션은 서버 측에서 관리하는 사용자 상태 정보이다.

- 클라이언트가 로그인하면, 세션 ID를 생성하여 저장
- 이후 클라이언트는 요청 시 세션 ID를 포함하여 서버로 전송
- 서버는 해당 ID를 확인하여 사용자 정보를 유지

세션의 동작 방식:

1. 클라이언트가 로그인 요청 (`POST /login`)
2. 서버가 세션을 생성하고 세션 ID를 쿠키로 발급 (`Set-Cookie: sessionId=123456`)
3. 이후 클라이언트 요청마다 `Cookie: sessionId=123456` 포함
4. 서버는 해당 세션 ID를 조회하여 사용자 정보 유지

쿠키는 클라이언트에서 관리되지만, 세션은 서버에서 관리된다.

**쿠키와 세션의 차이점은?**

저장 위치

- 쿠키: 클라이언트(브라우저)
- 세션: 서버

보안

- 쿠키: 데이터가 노출될 위험 있음
- 세션: 서버에서 관리되어 보안성이 높음

사용 방식

- 쿠키: 요청 시 자동으로 포함 (Cookie 헤더)
- 세션: 세션 ID를 기반으로 서버에서 사용자 정보 유지

유효 기간

- 쿠키: 설정 가능 (Session Cookie, Persistent Cookie)
- 세션: 일반적으로 일정 시간 후 만료

트래픽 부담

- 쿠키: 모든 요청마다 서버로 전송
- 세션: 서버 메모리 사용량 증가 가능

**HTTP는 무상태(Stateless)인데, 쿠키를 사용하면 어떻게 상태를 유지할 수 있나요?**

HTTP는 Stateless(무상태) 프로토콜이므로 요청과 응답이 끝나면 클라이언트의 상태를 기억하지 않는다. 그러나 쿠키를 활용하면 상태 유지가 가능하다.

쿠키를 이용한 상태 유지 방식:

1. 클라이언트가 서버에서 받은 쿠키를 브라우저에 저장
2. 이후 요청 시 쿠키를 자동으로 포함하여 서버로 전달
3. 서버는 쿠키를 확인하여 사용자를 식별

이 방식으로 로그인 상태 유지, 장바구니 정보 저장 등이 가능하다.

**세션 ID(Session ID)란?**

세션 ID는 사용자를 식별하기 위해 서버에서 발급하는 고유한 식별자이다.

- 서버는 세션 ID를 생성하고, 클라이언트의 쿠키에 저장 (`Set-Cookie: sessionId=abcdef123456`)
- 이후 요청 시 `Cookie: sessionId=abcdef123456`을 포함하여 서버로 전송
- 서버는 해당 ID를 확인하여 사용자 정보를 유지

세션 ID는 보안상 중요한 정보이므로 HTTPS를 사용하여 암호화해야 합니다.

**쿠키와 세션을 함께 사용하는 이유는?**

보안성과 확장성을 동시에 확보하기 위해 쿠키와 세션을 조합하여 사용한다.

쿠키 + 세션 동작 방식:

1. 로그인 성공 시, 서버는 세션 ID를 생성
2. 클라이언트에 세션 ID를 쿠키로 저장 (`Set-Cookie: sessionId=xyz123`)
3. 이후 요청마다 `Cookie: sessionId=xyz123` 포함하여 서버로 전송
4. 서버는 세션 ID를 확인하여 사용자 정보 조회

세션은 서버에서 관리하여 보안성을 높이고, 클라이언트는 가벼운 쿠키만 저장하여 효율성을 유지한다.

**쿠키의 생명주기(Lifetime)는 어떻게 설정하나요?**

쿠키는 유효 기간에 따라 `세션 쿠키`와 `영속 쿠키`로 나뉜다.

- 세션 쿠키: 브라우저 종료 시 자동 삭제
- 영속 쿠키: 특정 만료 날짜를 설정하여 브라우저 종료 후에도 유지

**쿠키 사용 시 주의할 점은?**

- 큰 데이터는 작은 패킷으로 나누어 전송되며,각 패킷이 다른 경로를 거쳐 도착할 수도 있고, 순서가 뒤바뀔 수도 있다.

**검증 헤더(Validation Header)란?**

검증 헤더는 캐시된 리소스가 최신 상태인지 확인하는 역할을 한다.

- 클라이언트가 캐시된 데이터가 유효한지 서버에 확인 요청
- 서버가 변경되지 않았으면 304 Not Modified 응답 (HTTP 바디 없음)
- 변경되었으면 새로운 데이터를 내려줌

불필요한 데이터 다운로드를 줄여 네트워크 트래픽을 절감할 수 있다.

**HTTP에서 캐시 유효 시간이 초과되었을 때, 서버는 어떻게 처리하나요?**

1. 서버에서 데이터가 변경되지 않은 경우
    - `304 Not Modified` 응답 (바디 없음)
    - 클라이언트가 기존 캐시된 데이터 사용
2. 서버에서 데이터가 변경된 경우
    - `200 OK` 응답
    - 새로운 데이터와 함께 응답

304 응답이 오면 기존 캐시를 재사용하고, 200 응답이면 새 데이터를 내려받습니다.

**검증 헤더와 조건부 요청을 사용하면 어떤 이점이 있나요?**

주요 장점

- 불필요한 데이터 전송 감소 → 변경되지 않은 데이터는 다시 다운로드하지 않음
- 네트워크 트래픽 절감 → 헤더 정보만 전송하면 되므로 응답 속도 개선
- 서버 부하 감소 → 변경된 데이터만 처리하여 성능 향상

효율적인 캐싱을 통해 네트워크 성능을 최적화할 수 있습니다.

**프록시 캐시란?**

프록시 캐시는 중간 서버에서 데이터를 캐싱하여 성능을 향상시키는 기법

- 클라이언트 요청을 받아 동일한 요청이 있을 경우 캐시된 응답을 제공
- 서버 부하 감소 & 네트워크 속도 개선

예제:

1. 웹 브라우저 1이 유튜브 영상을 다운로드
2. 프록시 서버가 해당 데이터를 캐싱
3. 웹 브라우저 2가 동일한 영상을 요청하면 프록시 캐시에서 빠르게 제공

동일한 리소스를 여러 사용자가 요청할 경우 프록시 캐시를 사용하면 성능을 크게 향상할 수 있다.

**Blocking과 Non-blocking의 차이는?**

Blocking과 Non-blocking은 "제어권(Control)"이 언제 반환되는지에 따라 구분.

- Blocking: 호출된 함수(B)가 자신의 작업을 끝낼 때까지 호출한 함수(A)가 기다림
    - 치킨집에서 주문 후, 치킨이 나올 때까지 가게에서 기다림
- Non-blocking: 호출된 함수(B)가 작업을 끝내지 않아도 즉시 호출한 함수(A)에게 제어권을 반환
    - 치킨집에서 주문 후, 볼일을 보다가 치킨이 준비되면 알려줌

**Synchronous와 Asynchronous의 차이는?**

Synchronous(동기)와 Asynchronous(비동기)는 "결과를 누가 신경 쓰는지"에 따라 구분.

- Synchronous (동기): 호출한 함수(A)가 호출된 함수(B)의 작업이 끝날 때까지 직접 확인하며 대기
    - 주문한 치킨이 나왔는지 계속 물어봄
- Asynchronous (비동기): 호출된 함수(B)가 작업이 끝나면 호출한 함수(A)에게 결과를 알려줌 (Callback)
    - 주문한 치킨이 다 되면 사장님이 직접 불러줌

동기는 요청한 함수가 결과를 계속 체크해야 하지만, 비동기는 결과가 준비되면 알려줍니다.

**Blocking & Synchronous vs Non-blocking & Asynchronous의 차이?**

Blocking & Synchronous (동기 + 블로킹)

- 호출된 함수(B)의 작업이 끝날 때까지 호출한 함수(A)가 계속 기다리고 있음
- 예: 치킨이 나올 때까지 가게에서 기다리면서 계속 치킨이 다 되었는지 확인

Non-blocking & Asynchronous (비동기 + 논블로킹)

- 호출된 함수(B)는 작업을 끝내지 않아도 호출한 함수(A)에게 제어권을 반환
- 작업이 끝나면 자동으로 결과를 알려줌 (Callback)
- 예: 치킨 주문 후, 가게를 떠나 다른 일을 하다가 치킨이 다 되면 사장님이 불러줌

Non-blocking & Asynchronous가 가장 효율적인 구조이며, 고성능 시스템에서 많이 사용.

**네트워크에서 Blocking과 Non-blocking은 어떻게 적용되나요?**

네트워크에서 Blocking과 Non-blocking은 소켓 프로그래밍에서 자주 사용.

- Blocking I/O: 데이터를 받을 때까지 프로그램이 멈춤
    - recv() 함수 호출 시, 데이터가 올 때까지 대기
- Non-blocking I/O: 데이터를 기다리지 않고, 바로 다음 작업 수행
    - recv() 함수가 데이터가 없으면 바로 반환

Blocking은 단순하지만 성능이 떨어지고, Non-blocking은 성능이 좋지만 복잡.

**네트워크에서 Synchronous와 Asynchronous는 어떻게 적용되나요?**

네트워크에서 동기/비동기는 "데이터를 처리하는 방식"에 영향을 준다.

- Synchronous I/O: 데이터가 도착했는지 계속 체크하며 대기
- Asynchronous I/O: 데이터가 도착하면 OS가 자동으로 알려줌 (이벤트 기반)

대규모 트래픽을 처리할 때는 Non-blocking & Asynchronous 방식이 유리하다.

**TCP와 UDP의 차이점은?**

TCP와 UDP는 데이터 전송을 담당하는 전송 계층(Transport Layer) 프로토콜이다.

**특징**

- TCP: 신뢰성이 높은 연결형 프로토콜
- UDP: 신뢰성보다 속도를 우선하는 비연결형 프로토콜

**연결 방식**

- TCP: 3-way Handshake를 통해 연결을 설정한 후 데이터 전송
- UDP: 연결 과정 없이 바로 데이터 전송

**데이터 전달 보장**

- TCP: 데이터 손실 없이 보장
- UDP: 데이터 손실 가능성 있음

**순서 보장**

- TCP: 패킷 순서를 유지하여 전송
- UDP: 패킷 순서 보장 없음

**속도**

- TCP: 느림 (오버헤드 발생)
- UDP: 빠름 (오버헤드 적음)

**사용 예시**

- TCP: HTTP, HTTPS, FTP, 이메일(SMTP, IMAP, POP3)
- UDP: 실시간 스트리밍, 온라인 게임, VoIP

**TCP의 특징은?**

TCP는 신뢰성 있는 데이터 전송을 보장하는 연결 지향 프로토콜.

- **3-way Handshake:** 데이터 전송 전에 연결을 설정하여 안정적인 통신을 보장.
- **데이터 전달 보장:** 패킷이 손실되면 재전송(ACK, Retransmission) 기능을 통해 복구.
- **순서 보장:** 패킷이 순서대로 도착하도록 조정.

**UDP의 특징은?**

UDP는 연결 없이 빠르게 데이터를 전송하는 프로토콜로, TCP보다 속도가 빠르지만 신뢰성이 낮다.

1. 연결 과정 없음 → 데이터가 바로 전송되므로 지연이 적음
2. 데이터 전달 보장 없음 → 패킷이 유실될 수 있음
3. 순서 보장 없음 → 패킷이 순서대로 도착하는 것을 보장하지 않음
4. 사용 예시 → 실시간 스트리밍, VoIP, 온라인 게임 등

**포트(Port)란?**

- 포트는 하나의 IP 주소에서 여러 개의 서비스를 구분하는 역할을 한다.
    - 예를 들어, 한 컴퓨터에서 동시에 웹 브라우징(80번 포트), 게임(8080번 포트), 이메일(25번 포트)을 실행할 수 있다.

**TCP/IP 패킷 구조는 어떻게 되어 있나요?**

TCP/IP 패킷은 IP 패킷 + TCP/UDP 헤더 + 데이터로 구성된다.

- **IP 패킷:** 출발지 IP, 목적지 IP 포함
- **TCP/UDP 헤더:** 포트 정보, 체크섬 등 포함
- **데이터:** 실제 전송할 내용

**TCP 3-Way Handshake란?**

TCP 3-Way Handshake는 TCP 연결을 설정하는 과정으로, 클라이언트와 서버가 서로를 신뢰할 수 있도록 한다.

1. 클라이언트 → 서버: `SYN` (연결 요청)
2. 서버 → 클라이언트: `SYN + ACK` (연결 요청 수락 & 확인)
3. 클라이언트 → 서버: `ACK` (연결 완료 확인)

**TCP 연결이 가상이라는 의미는?**

TCP 연결은 실제로 물리적인 선을 연결하는 것이 아니라, 여러 중계 장치를 거쳐 가더라도 논리적으로 연결된 것처럼 동작한다는 의미

즉, 우리가 직접 중간 경로를 알지 못해도 "연결되었다"고 믿고 통신을 진행한다.

**TCP에서 패킷의 순서는 어떻게 보장되나요?**

TCP는 순서 번호(Sequence Number) 를 사용하여 패킷의 순서를 유지.

- 패킷이 중간에 유실되면, 서버가 클라이언트에게 "2번부터 다시 보내!"(재전송 요청) 합니다.
- 클라이언트는 요청된 패킷만 재전송하여 순서가 맞게 조립됩니다.

이 과정은 TCP 패킷의 '전송 제어' 기능 덕분에 가능해진다.

**클라이언트가 서버에 요청을 보낼 때, 응답을 받을 수 있는 이유는?**

클라이언트가 요청을 보낼 때, 출발지 IP와 출발지 포트 번호를 포함하여 전송하기 때문

- 서버는 이 정보를 이용하여 클라이언트에게 정확한 응답을 보낼 수 있다.

즉, 패킷에는 '어디로 응답을 보내야 하는지' 정보가 포함되어 있다.

**DNS란?**

DNS는 도메인 이름을 IP 주소로 변환하는 시스템이다.

- IP 주소(예: `200.200.200.2`)는 기억하기 어렵고 변경될 수도 있음
- 대신 **도메인 이름(예: `www.google.com`)**을 사용하면 쉽고 편리함

DNS는 사람이 이해하기 쉬운 도메인 이름을 컴퓨터가 사용하는 IP 주소로 변환해준다.

**DNS는 어떻게 동작하나요?**

1. 사용자가 `www.example.com`에 접속하려고 하면,
2. 브라우저가 DNS 서버에 `www.example.com`의 IP 주소를 요청
3. DNS 서버가 해당 도메인의 IP 주소를 찾아서 반환
4. 브라우저는 반환된 IP 주소를 이용해 웹 서버에 접속

DNS는 '도메인 → IP 주소' 변환을 담당하여, 사용자가 쉽게 웹사이트에 접속할 수 있다.

**TCP/IP 스택이란?**

TCP/IP 스택은 네트워크 통신을 위한 4계층 모델로 구성된다.

- 응용 계층(Application Layer) → HTTP, FTP 등 애플리케이션이 직접 사용하는 프로토콜
- 전송 계층(Transport Layer) → TCP, UDP 등을 통해 데이터를 신뢰성 있게 전송
- 인터넷 계층(Internet Layer) → IP를 통해 데이터를 목적지로 라우팅
- 네트워크 인터페이스 계층(Network Interface Layer) → 물리적인 네트워크 장치와 연결

애플리케이션이 네트워크 기능을 직접 사용하지 않고, 시스템이 제공하는 소켓을 통해 데이터를 주고받는다.

**TCP에서 Connection과 Socket의 관계는?**

- Connection: 클라이언트와 서버 간의 논리적인 통신 경로
- Socket: `프로토콜 + IP 주소 + 포트 번호`를 합쳐 네트워크에서 고유하게 식별되는 주소

Connection은 두 개의 Socket 쌍으로 유일하게 식별 된다.

**TCP Connection을 유니크하게 식별하는 방법은?**

1. 출발지 IP (Source IP)
2. 출발지 Port (Source Port)
3. 목적지 IP (Destination IP)
4. 목적지 Port (Destination Port)

이 4가지 정보를 조합하면 동일한 포트라도 다른 연결에서 동시에 사용될 수 있다.

**흐름 제어(Flow Control)란?**

흐름 제어는 송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법이다.

- 수신측이 감당할 수 없는 데이터를 받지 않도록 송신 속도를 조절
- 송신자가 수신자의 수신 버퍼 크기를 고려하여 전송

수신 버퍼 초과로 인해 패킷이 손실되지 않도록 하는 것이 핵심이다.

**흐름 제어 방식에는 어떤 것들이 있나요?**

1. Stop and Wait (정지-대기)
    - 송신자가 패킷 하나를 전송한 후, 수신자로부터 확인 응답(ACK)을 받을 때까지 대기
    - 단점: 전송 속도가 매우 느림
2. Sliding Window (슬라이딩 윈도우)
    - 여러 개의 패킷을 연속해서 전송하고, ACK을 받으면 윈도우를 이동
    - 윈도우 크기만큼 송신할 수 있어 전송 속도가 향상됨

Sliding Window 방식이 Stop and Wait 방식보다 효율적이며, TCP에서도 사용된다.

**혼잡 제어(Congestion Control)란?**

혼잡 제어는 네트워크의 혼잡을 방지하기 위한 기법이다.

- 네트워크의 부하 상태를 감지하고 송신 속도를 조절
- 패킷 손실이 발생하기 전에 전송 속도를 줄여 혼잡을 예방

혼잡이 발생하면 패킷 손실이 증가하고, 재전송이 많아져 성능이 급격히 저하된다.

**혼잡 제어 방식에는 어떤 것들이 있나요?**

- AIMD
    - 송신 속도를 점진적으로 증가
    - 혼잡이 발생하면 전송 속도를 절반으로 감소
    - 단점: 초기에 전송 속도가 너무 느림
- Slow Start (느린 시작)
    - 처음에는 전송 속도를 지수적으로 증가 → 혼잡이 감지되면 AIMD로 전환
    - 초반에 빠르게 전송 속도를 올릴 수 있어 AIMD의 단점을 보완
- Fast Retransmit (빠른 재전송)
    - 수신측이 같은 패킷의 ACK을 3번 이상 중복해서 보내면 송신측이 즉시 재전송
    - 타이머가 만료될 때까지 기다리지 않고 빠르게 재전송 가능
- Fast Recovery (빠른 회복)
    - 혼잡이 감지되면 전송 속도를 1로 줄이지 않고, 절반으로 줄인 후 선형 증가
    - AIMD보다 빠르게 회복할 수 있음

Slow Start → AIMD → Fast Retransmit → Fast Recovery 순으로 동작한다.

**TCP의 혼잡 제어는 어떻게 동작하나요?**

1. Slow Start (느린 시작)
    - 처음에는 `cwnd = 1`로 시작하고, 매 RTT마다 2배씩 증가
    - 혼잡이 감지되면 Congestion Avoidance로 전환
2. Congestion Avoidance (혼잡 회피)
    - 혼잡이 발생하기 전까지 cwnd를 선형 증가(AIMD 적용)
    - 패킷 손실이 발생하면 `Fast Retransmit` 수행
3. Fast Retransmit (빠른 재전송)
    - 동일한 ACK이 3번 중복되면 즉시 패킷 재전송
4. Fast Recovery (빠른 회복)
    - cwnd를 1로 초기화하지 않고 절반으로 줄인 후 선형 증가

이 과정을 반복하며 네트워크 상태에 맞춰 송신 속도를 조절한다.

**Slow Start와 AIMD의 차이점은?**

전송 속도 증가 방식

- Slow Start: 지수 증가 (2배씩 증가)
- AIMD: 선형 증가 (1씩 증가)

혼잡 감지 후 동작

- Slow Start: Congestion Avoidance로 전환
- AIMD: 송신 속도를 절반으로 줄이고 선형 증가

초기 속도 증가

- Slow Start: 빠름
- AIMD: 느림

**혼잡 제어와 흐름 제어를 동시에 적용하는 이유는?**

- 흐름 제어 → 수신자의 수신 버퍼 크기를 고려하여 송신 속도를 조절
- 혼잡 제어 → 네트워크 상태를 고려하여 송신 속도를 조절

수신자가 감당할 수 있는 속도와 네트워크의 혼잡 상태를 모두 고려해야 최적의 송신 속도를 유지할 수 있다.

**UDP란?**

UDP는 TCP와 달리 연결을 설정하지 않고 데이터를 전송하는 프로토콜이다.

- Connectionless → 연결을 맺지 않고 바로 데이터 전송
- Unreliable → 신뢰성이 없으며, 데이터 손실 가능성이 있음
- 빠름 → TCP보다 속도가 빠르며, 간단한 에러 체크만 수행

UDP는 신뢰성보다 속도가 중요한 실시간 스트리밍, 온라인 게임 등에 사용된다.

**UDP의 특징은?**

- 비연결형(Connectionless) → 3-way handshake 없이 전송
- 신뢰성이 없음(Unreliable) → 데이터 손실 가능 (재전송 없음)
- 빠름(Low Overhead) → TCP보다 헤더가 작고, 네트워크 부하 적음
- 순서 보장 안됨(Out of Order) → 패킷 순서가 뒤바뀔 수 있음

UDP는 속도가 중요한 실시간 서비스(스트리밍, 온라인 게임 등)에 사용된다.

**UDP와 TCP의 차이점은?**

연결 방식

- UDP: 비연결형 (Connectionless)
- TCP: 연결형 (Connection-Oriented)

데이터 전송 방식

- UDP: 빠르게 전송, 신뢰성 없음
- TCP: 신뢰성 있는 전송 (순서 보장, 재전송)

오버헤드

- UDP: 적음 (헤더 크기 작음)
- TCP: 큼 (3-way handshake, 흐름 제어, 혼잡 제어)

데이터 순서 보장

- UDP: 불가능
- TCP: 가능

재전송 기능

- TCP: UDP: 없음
- 있음

대표적인 사용 사례

- UDP: 실시간 스트리밍, VoIP, 온라인 게임, DNS
- TCP: 웹사이트, 이메일, 파일 전송

속도가 중요한 경우 UDP, 신뢰성이 중요한 경우 TCP를 사용합니다.

**UDP는 왜 사용할까요?**

UDP의 큰 장점은 "빠른 데이터 전송"이다.

- 데이터 전송 속도가 TCP보다 빠름
- 오버헤드가 낮아 네트워크 부하가 적음
- 손실이 발생해도 실시간성이 중요한 애플리케이션에서는 허용 가능

**UDP 사용 사례:**

- 실시간 스트리밍 (YouTube, Netflix) → 일부 패킷 손실이 발생해도 영상이 재생되어야 함
- VoIP(인터넷 전화) → 전화 통화에서 약간의 데이터 손실보다 지연 없는 통신이 중요
- 온라인 게임 → 속도가 중요하며, 일부 패킷 손실이 게임 플레이에 큰 영향을 미치지 않음
- DNS → 작은 데이터 요청은 빠르게 응답해야 함

속도가 중요한 서비스에서는 신뢰성을 일부 포기하고 UDP를 사용한다.

**DNS는 왜 UDP를 사용할까요?**

DNS는 작은 데이터 요청을 빠르게 처리해야 하기 때문에 UDP를 사용한다.

**UDP에서 데이터 손실이 발생하면 어떻게 해결하나요?**

UDP 자체에는 재전송 기능이 없지만, 애플리케이션에서 보완할 수 있다.

UDP에서 데이터 손실을 해결하는 방법:

- 애플리케이션 레벨에서 신뢰성 추가 → (예: 실시간 스트리밍에서 패킷 복구 알고리즘 사용)
- 중복된 패킷을 보내는 방식 (FEC, Forward Error Correction) → 일부 손실 방지
- 패킷 손실을 감지하고 필요한 경우 재전송 요청 (ARQ, Automatic Repeat reQuest)

TCP처럼 복잡한 흐름 제어나 재전송이 필요하지 않은 경우 UDP를 사용하고, 필요한 경우 애플리케이션에서 보완한다.

**네트워크(Network)란?**

네트워크는 컴퓨터나 기타 기기들이 데이터를 주고받거나 리소스를 공유하기 위해 유선 또는 무선으로 연결된 통신 체계이다.

**네트워크의 주요 기능:**

- 애플리케이션 간 통신 방법 제공
- 신뢰할 수 있는 데이터 전송 보장
- 네트워크 간 최적의 경로 결정
- 목적지로 데이터 전송
- 노드 간 데이터 전송

**네트워크 통신을 위해 필요한 것은?**

네트워크 통신을 위해서는 약속된 규칙(프로토콜)이 필요하다.

- 이를 네트워크 프로토콜이라고 하며, 데이터 형식, 절차, 규약을 정의한다.

하나의 프로토콜로 모든 기능을 구현할 수 없기 때문에 계층화(Layered Architecture)가 필요하다.

**URI란?**

URI는 리소스를 식별하는 통일된 방법이다.

- 웹에서 리소스(HTML 파일, API 데이터, 이미지, 동영상 등)를 식별할 때 사용된다.

**웹 브라우저에서 요청을 보낼 때의 전체 흐름은?**

1) DNS 조회 (도메인 → IP 변환)

- 사용자가 `https://www.google.com` 입력
- 브라우저가 DNS 조회를 통해 `www.google.com → 200.200.200.2`(IP 주소) 변환
- `https` 프로토콜이므로 기본 포트는 `443` 사용

2) HTTP 요청 메시지 생성

- `GET /search?q=hello&hl=ko HTTP/1.1` 요청 생성
- 헤더에 Host, User-Agent, Accept 등의 정보 포함

3) TCP 연결 (3-Way Handshake)

- 찾은 IP(200.200.200.2) 와 포트(443) 를 이용해 TCP 연결 생성
- 3-Way Handshake 진행 (SYN → SYN+ACK → ACK)

4) HTTP 요청 전송 (패킷 생성 & 전송)

- HTTP 요청을 TCP/IP 패킷에 포함하여 전송
- 네트워크 인터페이스 계층을 통해 서버로 전송

5) 서버에서 요청 처리

- 서버가 TCP 패킷을 해석하여 HTTP 요청 메시지를 추출
- 요청된 URL(`https://www.google.com/search?q=hello&hl=ko`)을 분석
- 해당 요청에 대한 응답 HTML 페이지 생성

6) HTTP 응답 생성 & 전송

- 서버에서 HTTP 응답 메시지 생성
- `HTTP/1.1 200 OK` 상태 코드와 함께 HTML 데이터를 포함
- HTTP 응답을 다시 TCP/IP 패킷으로 감싸 전송

7) 클라이언트에서 응답 수신 & 웹 페이지 렌더링

- 클라이언트가 TCP/IP 패킷을 해석하여 HTTP 응답 메시지 추출
- HTML, CSS, JavaScript 데이터를 브라우저에서 해석
- 최종적으로 웹 페이지 렌더링하여 사용자에게 표시

결과적으로 사용자는 웹 페이지를 볼 수 있습니다.

**웹 요청이 서버로 전달되는 과정에서 어떤 계층이 동작하나요?**

웹 요청은 각 계층을 거쳐 서버로 전달된다.

1. L7 (응용 계층) → HTTP 요청 생성 (`GET /search?q=hello HTTP/1.1`)
2. L4 (전송 계층) → TCP 3-Way Handshake 연결 후 HTTP 데이터 전송
3. L3 (네트워크 계층) → IP 주소를 이용해 패킷을 목적지로 전달
4. L2 (데이터 링크 계층) → MAC 주소를 기반으로 네트워크 장치 간 전달
5. L1 (물리 계층) → 전기 신호 또는 무선 신호로 데이터를 전송

서버에서도 동일한 과정을 거꾸로 수행하여 요청을 처리하고 응답을 반환합니다.

**웹 브라우저가 HTML을 받아서 화면에 표시하는 과정은?**

1. 브라우저가 HTTP 응답 메시지를 분석하여 HTML, CSS, JS 등 리소스를 가져옴
2. HTML 파싱 → DOM(Document Object Model) 트리 생성
3. CSS 파싱 → CSSOM(CSS Object Model) 생성
4. 두 개를 결합하여 렌더 트리(Render Tree) 생성
5. 브라우저가 렌더 트리를 기반으로 레이아웃(Layout) 계산
6. 최종적으로 픽셀을 화면에 렌더링(Rendering)

**클라이언트-서버 구조란?**

클라이언트-서버 구조는 클라이언트가 요청을 보내고, 서버가 응답을 반환하는 모델이다.

- 클라이언트 → UI 담당 (화면을 그리고 사용자 입력을 처리)
- 서버 → 비즈니스 로직, 데이터 관리 담당

클라이언트는 UI에 집중하고, 서버는 데이터 처리와 비즈니스 로직을 담당하여 역할을 분리

**클라이언트-서버 구조의 동작 방식은?**

1. 클라이언트가 요청(Request) 생성
    - 예: 사용자가 `로그인 버튼` 클릭
    - 브라우저가 서버로 `HTTP 요청` 전송
2. 서버가 요청 처리
    - 요청된 데이터를 조회하거나, 비즈니스 로직 실행
3. 서버가 응답(Response) 반환
    - 요청 처리 결과(예: 로그인 성공/실패)를 HTTP 응답으로 반환
4. 클라이언트가 응답을 받아 UI 업데이트
    - 로그인 성공 시 `홈 화면`으로 이동

서버는 요청이 올 때까지 기다리며, 클라이언트가 요청을 보내야 동작한다.

**Stateful과 Stateless의 차이점은?**

Stateful(상태 유지)과 Stateless(무상태)

**특징**

- Stateful: 서버가 클라이언트의 상태를 기억
- Stateless: 서버가 상태를 기억하지 않음

**요청 방식**

- Stateful: 클라이언트의 상태 정보를 저장하고 유지
- Stateless: 클라이언트가 매 요청마다 모든 정보를 포함

**확장성**

- Stateful: 서버 증설이 어려움 (세션 동기화 필요)
- Stateless: 서버 증설이 용이 (로드 밸런싱 가능)

**예시**

- Stateful: 로그인 세션 유지, 은행 거래 시스템
- Stateless: REST API, 검색 엔진

Stateful은 서버가 상태를 기억해야 하지만, Stateless는 각 요청이 독립적이어서 서버를 유연하게 확장할 수 있다.

**Stateful 방식의 문제점은?**

- 장애 발생 시 문제 → 서버가 다운되면 상태가 유지되지 않아 클라이언트가 처음부터 다시 요청해야 함
- 확장성 문제 → 여러 개의 서버를 운영하려면 모든 서버가 같은 상태 정보를 공유해야 함
- 부하 증가 → 사용자 수가 많아지면 서버의 상태 저장 부담이 증가

서버 증설이 어렵고, 장애 발생 시 서비스 지속성이 낮아질 수 있다.

**Stateless 방식의 장점은?**

- 확장성 증가 → 서버를 추가해도 상태를 공유할 필요가 없어 로드 밸런싱이 용이
- 장애 대응이 쉬움 → 특정 서버가 다운되면 다른 서버가 동일한 요청을 처리 가능
- 유지보수 용이 → 상태를 저장하지 않으므로 서버 간 동기화가 필요 없음

Stateless는 서버가 상태를 기억하지 않아, 무한한 서버 증설이 가능하고 장애 복구가 용이.

**Stateless 설계가 중요한 이유는?**

- 확장성 문제 해결 → 서버를 쉽게 추가하여 트래픽을 분산 가능
- 장애 대응 → 한 서버가 다운되어도 다른 서버에서 처리 가능
- 유지보수 용이 → 상태 저장이 없으므로 서버 간 동기화가 필요 없음

선착순 이벤트, 명절 KTX 예약, 수강 신청 같은 대량 트래픽 환경에서는 반드시 Stateless 구조가 필요하다.

**비연결성이란?**

- 비연결성이란 클라이언트와 서버가 지속적으로 연결을 유지하지 않는 모델이다.
- 클라이언트가 요청을 보내고 응답을 받으면 즉시 연결을 종료
- 필요할 때마다 새로운 연결을 생성하여 최소한의 서버 자원을 사용

HTTP는 기본적으로 비연결 모델을 사용

**비연결성의 장점과 단점은?**

**장점**

- 서버 자원 절약 → 사용자가 요청을 보내지 않을 때는 연결을 유지하지 않아 불필요한 리소스를 소비하지 않음
- 확장성(Scalability) → 서버가 동시에 처리해야 하는 요청 수를 줄일 수 있음

**단점**

- 반복적인 연결 생성 비용 → 요청마다 새로운 연결을 맺어야 해서 추가적인 시간과 비용 발생
- 연속적인 요청 처리 어려움 → 동일한 클라이언트가 여러 요청을 보낼 경우, 각 요청이 독립적으로 처리됨

HTTP는 기본적으로 비연결성이지만, 지속적인 연결 방식으로 단점을 해결할 수 있다.

**HTTP가 비연결성을 사용하는 이유는?**

- HTTP는 일반적으로 짧은 시간 내에 응답을 반환
- 클라이언트가 요청하지 않을 때 서버 자원을 낭비하지 않기 위해
- 실제로 수천 명이 접속해도 동시에 처리해야 할 요청은 적기 때문

비연결성 덕분에 HTTP는 서버 자원을 효율적으로 사용할 수 있다.

**비연결성의 문제를 해결하는 방법은?**

HTTP 지속 연결

- 요청마다 새로운 연결을 맺지 않고 한 번 연결하면 여러 요청을 처리할 수 있도록 유지
- HTTP/1.1부터 기본적으로 `Connection: keep-alive` 설정
- 불필요한 연결 설정 비용을 줄이고, 성능을 개선

HTTP 지속 연결을 통해 비연결성의 단점을 보완할 수 있다.

**멱등(Idempotent)이란?**

멱등이란 같은 요청을 여러 번 보내더라도 결과가 항상 동일한 성질을 의미.

- 1번 호출하든, 100번 호출하든 같은 결과를 반환해야 함

HTTP에서 멱등한 메서드는 같은 요청을 반복해도 상태가 변하지 않는다.

**멱등성을 유지하는 이유는?**

자동 복구 메커니즘 지원

- 서버가 응답을 주지 못했을 때 클라이언트가 동일 요청을 재시도할 수 있음

안전한 요청 재전송 가능

- 네트워크 장애 등으로 인해 요청이 중복 전송될 경우 예상치 못한 부작용 방지

캐싱(Cache) 최적화

- GET 요청을 캐싱하여 불필요한 네트워크 요청을 줄일 수 있음

멱등성을 유지하면 서버 장애 복구와 네트워크 효율성을 높일 수 있다.

**HTTP 캐싱을 사용하는 이유는?**

캐싱을 사용하면 네트워크 트래픽을 줄이고 성능을 향상시킬 수 있다.

- 성능 향상 → 동일한 요청을 캐싱하면 서버 응답 시간을 줄일 수 있음
- 트래픽 감소 → 불필요한 네트워크 요청을 최소화
- 서버 부하 감소 → 동일한 요청을 반복해서 처리하지 않아도 됨

GET 요청의 결과를 캐싱하면, 동일한 리소스를 다시 요청할 필요가 없다.

**HTTP 상태 코드란?**

HTTP 상태 코드는 클라이언트 요청에 대한 서버의 응답 상태를 나타낸다.

1xx (정보)

- 요청을 수신했고, 처리 중

2xx (성공)

- 요청 정상 처리

3xx (리다이렉션)

- 추가 작업 필요 (다른 URL로 이동)

4xx (클라이언트 오류)

- 클라이언트 잘못된 요청

5xx (서버 오류)

- 서버가 정상 처리 불가

**리다이렉트란?**

리다이렉트는 클라이언트가 요청한 URL이 변경되었을 때, 자동으로 새로운 URL로 이동하는 기능이다.

- 3xx 상태 코드와 함께 `Location` 헤더에 새로운 URL을 포함하여 응답
1. `/event` 요청 → 서버가 `301 Moved Permanently` 응답 (`Location: /new-event`)
2. 클라이언트가 `/new-event`로 자동 요청

리다이렉트는 사용자가 직접 입력하지 않아도 새로운 URL로 이동하게 한다.

**PRG(Post/Redirect/Get) 패턴이란?**

- PRG(Post/Redirect/Get) 패턴은 POST 요청 후 중복 요청을 방지하기 위해 리다이렉트를 사용하는 기법이다.

**PRG를 사용하지 않은 경우**

1. 사용자가 POST 요청으로 주문
2. 응답을 받고 새로고침
3. POST 요청이 다시 실행되며 중복 주문 발생

**PRG를 사용한 경우**

1. 사용자가 POST 요청으로 주문
2. 서버가 302/303 상태 코드와 함께 GET 요청으로 리다이렉트
3. 사용자가 새로고침해도 GET 요청이 실행되므로 중복 주문 방지

PRG 패턴을 사용하면 중복 데이터 전송 문제를 해결할 수 있다.

**로드 밸런싱(Load Balancing)이란?**

로드 밸런싱은 여러 서버에 트래픽을 분산시켜 부하를 균등하게 조절하는 기술이다.

- 하나의 서버가 과부하로 다운되는 것을 방지
- 여러 대의 서버(Scale-out)로 트래픽을 분산하여 성능 향상 & 가용성 증가

**로드 밸런싱이 필요한 이유**

- 트래픽이 급격히 증가할 경우 단일 서버가 모든 요청을 처리하기 어려움
- Scale-up(서버 성능 업그레이드)보다 Scale-out(서버 추가)이 비용 대비 효과적
- 무중단 서비스(High Availability) 제공

로드 밸런서는 클라이언트와 서버 사이에서 트래픽을 적절히 분배하는 역할을 한다.

**로드 밸런서(Load Balancer)의 동작 방식은?**

로드 밸런서는 여러 서버에 클라이언트 요청을 분배하여 부하를 조절한다.

1. 클라이언트가 서버 요청을 보냄
2. 로드 밸런서가 트래픽을 감지하고, 적절한 서버로 요청을 전달
3. 서버가 요청을 처리하고, 클라이언트에게 응답 반환

로드 밸런서 덕분에 모든 요청이 한 서버에 집중되지 않고, 여러 서버에 분산 된다.

**로드 밸런서가 트래픽을 분배하는 방식에는 어떤 것들이 있나요?**

로드 밸런서는 다양한 알고리즘을 사용하여 요청을 적절한 서버로 분배한다.

- **라운드 로빈:** 서버 목록을 순서대로 돌아가며 요청을 분배
    - 모든 서버가 균등하게 트래픽을 처리 (가장 기본적인 방식)
- **가중치 라운드 로빈:** 서버별 가중치를 설정하여 요청을 분배
    - 서버 성능에 따라 부하를 차등 분배
- **최소 연결 방식:** 현재 연결 수가 가장 적은 서버에 요청 전송
    - 세션이 오래 유지되는 서비스에서 효과적
- **IP 해싱:** 사용자 IP를 해싱하여 특정 서버로 요청 전달
    - 같은 사용자는 항상 같은 서버로 연결됨 (세션 유지)
- **응답 시간 기반:** 응답 속도가 가장 빠른 서버로 요청 전송
    - 성능이 가장 좋은 서버를 우선 사용

**로드 밸런서를 사용하면 어떤 장점이 있나요?**

1. 성능 향상
- 트래픽이 여러 서버로 분산되어 각 서버의 부하를 줄이고 응답 속도를 개선
1. 고가용성
- 특정 서버가 다운되더라도 다른 서버가 요청을 처리하여 서비스 지속 가능
1. 확장성
- 서버를 추가하여 트래픽 증가에 유연하게 대응 가능
1. 보안 강화
- 클라이언트 요청이 직접 서버로 전달되지 않으므로 보안 위험 감소

로드 밸런싱을 통해 성능, 가용성, 보안을 모두 향상할 수 있다.

**Blocking/Non-blocking과 Synchronous/Asynchronous를 함께 설명할 수 있나요?**

- Blocking & Synchronous: 치킨이 나올 때까지 가게에서 기다리면서 계속 확인
    - while(치킨 안나옴) { 계속 확인 }
- Blocking & Asynchronous: 치킨이 나올 때까지 가게에서 기다리지만, 치킨이 다 되면 사장님이 알려줌
    - while(치킨 안나옴) { 사장님이 불러줄 때까지 대기 }
- Non-blocking & Synchronous: 치킨집을 떠나서 볼일을 보지만, 계속 전화해서 치킨이 나왔는지 확인
    - while(치킨 안나옴) { 일정 시간마다 확인 }
- Non-blocking & Asynchronous: 치킨집을 떠나서 볼일을 보고, 치킨이 다 되면 사장님이 전화로 알려줌
    - 치킨이 나오면 사장님이 콜백 호출

고성능 시스템에서는 Non-blocking & Asynchronous 방식이 가장 많이 사용.

**언제 Blocking & Synchronous, Non-blocking & Asynchronous를 사용해야 하나요?**

Blocking & Synchronous (단순한 작업에 적합)

- 작은 규모의 애플리케이션
- 응답 시간이 짧고, 다중 처리가 필요하지 않은 경우

Non-blocking & Asynchronous (고성능 시스템에 적합)

- 대규모 트래픽을 처리하는 서버 (웹 서버, 게임 서버)
- 실시간 데이터 스트리밍 (유튜브, 넷플릭스)
- 멀티스레드 환경에서 동시성을 최적화해야 하는 경우

단순한 경우에는 Blocking & Synchronous, 고성능 시스템에서는 Non-blocking & Asynchronous를 사용.

**자바스크립트의 비동기 처리(Async/Await, Promise)는 어떻게 동작하나요?**
자바스크립트의 비동기 처리 방식 (Event Loop 기반)

- Callback: 비동기 작업이 끝나면 함수를 실행하는 방식
- Promise: then()을 사용하여 비동기 결과를 처리
- Async/Await: 비동기 코드를 동기 코드처럼 작성 가능

자바스크립트는 기본적으로 Non-blocking & Asynchronous 방식이다.

**동기(Synchronous)보다 비동기(Asynchronous)가 항상 좋은가요?**

비동기는 효율적이지만, 항상 더 좋은 것은 아닙니다.

- 비동기 장점: 많은 요청을 동시에 처리 가능
    - CPU 사용률 최적화
- 비동기 단점: 코드가 복잡해지고 디버깅이 어려움
    - 응답 시간이 예측하기 어려움

작업이 많고 성능이 중요한 경우 비동기를, 단순한 작업은 동기 방식을 선택한다.
